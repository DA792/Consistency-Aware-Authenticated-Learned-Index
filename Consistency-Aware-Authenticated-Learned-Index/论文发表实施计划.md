# 论文发表实施计划 (CCF C / 中文期刊)

## 📅 时间规划 (3-4周)

### Week 1: Baseline实现 + 初步对比
- [ ] 实现Merkle Hash Tree (MHT)
- [ ] 实现Grid索引 + 哈希验证
- [ ] 实现传统R-tree (无学习模型)
- [ ] 完成三个Baseline的性能测试

### Week 2: 真实数据集 + 全面实验
- [ ] 下载并处理真实数据集 (OSM/Gowalla)
- [ ] 在多个数据集上运行对比实验
- [ ] 收集完整的性能数据
- [ ] 生成对比图表

### Week 3: 理论分析 + 论文撰写
- [ ] 完成复杂度分析
- [ ] 完成VO大小理论分析
- [ ] 撰写论文初稿 (引言/相关工作/方法)
- [ ] 撰写实验部分

### Week 4: 完善 + 投稿
- [ ] 论文修改润色
- [ ] 准备投稿材料
- [ ] 选择目标期刊/会议
- [ ] 提交投稿

---

## 🎯 目标期刊/会议

### 推荐1: **DASFAA 2026** (CCF B，但很适合)
```
📅 截稿时间: 2025年12月 (预计)
📍 会议地点: 亚洲
📊 接收率: ~30%
✅ 优势:
  - 数据库领域主流会议
  - 对索引技术友好
  - 接收率相对高
  - 认可度好
```

### 推荐2: **中文核心期刊**
```
1. 《计算机研究与发展》(CCF A中文)
   - 审稿周期: 6-8个月
   - 难度: ⭐⭐⭐⭐
   - 影响因子: 较高

2. 《软件学报》(CCF A中文)
   - 审稿周期: 6-9个月
   - 难度: ⭐⭐⭐⭐
   - 认可度高

3. 《计算机学报》
   - 审稿周期: 6-8个月
   - 难度: ⭐⭐⭐⭐
   
4. 《通信学报》
   - 审稿周期: 4-6个月
   - 难度: ⭐⭐⭐
   - 更容易接收
```

### 推荐3: **国际CCF C会议**
```
1. WISE (Web Information Systems Engineering)
   - 难度: ⭐⭐
   - 接收率: 35-40%
   
2. APWeb (Asia Pacific Web Conference)
   - 难度: ⭐⭐
   - 接收率: 30-35%
```

---

## 📊 需要补充的实验

### 1. Baseline实现

#### Baseline 1: **Merkle Hash Tree (MHT)**
```
经典的认证数据结构

实现要点:
  - 构建二叉Merkle树
  - 叶子节点存储数据哈希
  - 范围查询返回验证路径
  
对比指标:
  - 查询时间 (预计: 比PVL慢3-5倍)
  - 验证时间 (预计: 类似)
  - VO大小 (预计: 类似)
  - 构建时间 (预计: 更快)
```

#### Baseline 2: **Grid索引 + 哈希链**
```
简单的空间分区 + 验证

实现要点:
  - 将空间划分为Grid (如32×32)
  - 每个Cell构建哈希链
  - 查询时返回相关Cells的VO
  
对比指标:
  - 查询时间 (预计: 小查询更快,大查询慢)
  - 验证时间 (预计: 类似)
  - VO大小 (预计: 更大)
```

#### Baseline 3: **传统R-tree (无学习模型)**
```
经典空间索引

实现要点:
  - 使用现成R-tree库
  - 添加Merkle哈希验证
  
对比指标:
  - 查询时间 (预计: 小查询更慢,大查询更快)
  - 验证时间 (预计: 类似)
  - 树深度 (预计: 更深)
```

---

### 2. 真实数据集

#### 数据集1: **OpenStreetMap (OSM)**
```
📍 类型: 真实POI位置数据
📊 规模: 100K - 10M点
🔗 下载: https://download.geofabrik.de/

使用:
  - 提取经纬度坐标
  - 归一化到[0, 10^9]
  - 测试真实数据分布
```

#### 数据集2: **Gowalla签到数据**
```
📍 类型: 用户签到位置
📊 规模: ~6.4M签到记录
🔗 下载: SNAP数据集

使用:
  - 提取GPS坐标
  - 测试聚集分布
```

#### 数据集3: **T-Drive出租车轨迹**
```
📍 类型: 北京出租车GPS轨迹
📊 规模: ~15M GPS点
🔗 下载: Microsoft Research

使用:
  - 测试移动对象场景
  - 验证动态查询性能
```

---

### 3. 实验维度

#### 维度1: **数据规模**
```
测试: 10K, 50K, 100K, 500K, 1M, 5M

指标:
  - 构建时间 vs 数据规模
  - 查询时间 vs 数据规模
  - 内存占用 vs 数据规模
```

#### 维度2: **查询选择性**
```
测试: 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1

指标:
  - 查询时间 vs 选择性
  - 验证时间 vs 选择性
  - VO大小 vs 选择性
  - 假阳性率 vs 选择性
```

#### 维度3: **误差界限 (err)**
```
测试: 32, 64, 128, 256, 512

指标:
  - 查询时间 vs err
  - 验证时间 vs err
  - 假阳性率 vs err
  - 树深度 vs err
```

#### 维度4: **分区数量**
```
测试: 无分区, 4, 8, 16, 32分区

指标:
  - 查询时间 vs 分区数
  - 验证时间 vs 分区数
  - VO大小 vs 分区数
```

#### 维度5: **数据分布**
```
测试:
  - 均匀分布 (Uniform)
  - 高斯分布 (Gaussian)
  - 聚集分布 (Clustered)
  - 真实数据 (OSM/Gowalla/T-Drive)

指标:
  - 各分布下的综合性能对比
```

---

## 📝 理论分析补充

### 1. 复杂度分析

#### 构建复杂度
```
1. Z-order排序: O(n log n)
2. PVL树构建: O(n)
3. 分区构建: O(n/k) × k = O(n)
   k = 分区数

总构建时间: O(n log n)
```

#### 查询复杂度
```
1. Z-order分解: O(d)  d=Z区间数
2. 每个Z区间查询: O(log n + m)  m=结果数
3. 空间过滤: O(m)

总查询时间: O(d × log n + m)

优化后 (分区):
  - 相关分区数: p (p << k)
  - 每分区查询: O(log(n/k) + m/p)
  
总时间: O(p × log(n/k) + m)
       = O(p × log n - p × log k + m)
```

#### 验证复杂度
```
1. 验证路径长度: O(log n)
2. Z区间数: O(d)
3. 哈希计算: O(d × log n)

总验证时间: O(d × log n)

优化后 (分区):
  O(p × log(n/k)) 
  = O(p × log n - p × log k)
```

#### 空间复杂度
```
1. 原始数据: O(n)
2. Z-order映射: O(n)
3. PVL树: O(n)
4. 分区元数据: O(k)

总空间: O(n)
```

---

### 2. VO大小分析

#### 理论界
```
最坏情况:
  - Z区间数: d_max = O(√n)
  - 每区间VO: O(log n)
  - VO总大小: O(√n × log n)

平均情况:
  - Z区间数: d_avg = O(log A)  A=查询面积
  - VO总大小: O(log A × log n)

优化后 (分区):
  - 相关分区: p
  - VO大小: O(p × log(n/k))
           = O(p × log n - p × log k)
  
  当 k = √n 时:
  VO大小 = O(p × log n - p/2 × log n)
         = O(p/2 × log n)
  
  理论上减少50%! ✓
```

---

### 3. 参数选择理论

#### 最优分区数推导
```
目标: 最小化查询时间

查询时间 T(k):
  T(k) = T_locate + T_query + T_merge
  
  T_locate = O(log k)     # 定位分区
  T_query = p × O(log(n/k))  # 查询p个分区
  T_merge = O(m)          # 合并结果
  
  T(k) ≈ c1·log k + c2·p·(log n - log k) + c3·m
  
对k求导,令 dT/dk = 0:
  c1/k - c2·p/k = 0
  => k* = c2·p / c1
  
简化:
  当 p ≈ √k 时 (查询覆盖√k个分区)
  k* ≈ √n
  
结论: 最优分区数约为 √n

对于n=500K: k* ≈ √500000 ≈ 707
对于n=1M:   k* ≈ √1000000 = 1000

实践中选择: k = 8~32 (考虑并行度)
```

#### 最优误差界限推导
```
目标: 平衡查询速度和假阳性

假阳性率 FP(err):
  FP(err) = O(err / n)  # 每段预测误差err
  
查询时间 T(err):
  树深度 h(err) = O(log_err n)
  T(err) = O(h(err)) = O(log n / log err)
  
综合代价:
  Cost = α·T(err) + β·FP(err)
       = α·log n / log err + β·err/n
       
对err求导,令 dCost/derr = 0:
  -α·log n / (err·(log err)²) + β/n = 0
  
  err* ≈ O(√(α·n·log n / β))
  
对于n=500K, 取α=β:
  err* ≈ 128~256 ✓ (与实验一致!)
```

---

## 📈 论文结构

### 中文期刊论文结构 (建议)

```
标题: 面向二维空间范围查询的自适应分区学习索引

摘要 (300字)
  - 背景: 空间数据查询 + 可验证性需求
  - 问题: 现有方法查询慢/VO大
  - 方法: Z-order分区 + PVL学习索引
  - 结果: 查询快60%, VO小20%

1. 引言
  1.1 研究背景
  1.2 相关工作
  1.3 本文贡献
  1.4 论文组织

2. 预备知识
  2.1 认证数据结构
  2.2 Z-order曲线
  2.3 分段线性拟合

3. 问题定义
  3.1 系统模型
  3.2 安全模型
  3.3 问题陈述

4. 索引设计
  4.1 整体架构
  4.2 Z-order映射
  4.3 PVL树构建
  4.4 分区策略
  4.5 查询算法
  4.6 验证算法

5. 理论分析
  5.1 复杂度分析
  5.2 VO大小分析
  5.3 参数选择
  5.4 安全性分析

6. 实验评估
  6.1 实验设置
  6.2 数据集
  6.3 对比方法
  6.4 性能评估
    6.4.1 查询性能
    6.4.2 验证性能
    6.4.3 VO大小
    6.4.4 参数影响
    6.4.5 可扩展性
  6.5 真实数据集验证

7. 结论与展望
  7.1 工作总结
  7.2 未来工作

参考文献 (30-50篇)
```

---

## 🚀 立即开始的任务

### 任务1: 实现第一个Baseline (MHT)

我现在帮你实现 **Merkle Hash Tree** 作为第一个对比方案?

这是最基础也是最重要的Baseline,大约需要:
- MerkleHashTree.java (核心实现)
- MHTQueryResult.java (查询结果)
- MHTTest.java (性能测试)
- 约300行代码,1-2小时完成

### 任务2: 准备数据集下载脚本

我可以创建脚本自动下载和处理真实数据集:
- download_datasets.py (下载OSM/Gowalla数据)
- process_datasets.py (数据清洗和格式转换)

---

## 🎯 你想从哪个任务开始?

**选项**:
1. ✅ **实现MHT Baseline** (最优先,建立对比基准)
2. 📊 **准备数据集** (下载真实数据)
3. 📝 **开始写论文框架** (边实验边写)
4. 🔧 **优化现有代码** (完善分区索引)

**推荐**: 先做**选项1**,因为:
- MHT是最重要的Baseline
- 实现后立即可以对比性能
- 有了对比数据,更清楚论文的卖点
- 约2小时完成,立即见效

**需要我现在实现MHT吗?** 🚀








